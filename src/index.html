<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
  <title>Ionic App</title>
  <meta name="viewport" content="viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="format-detection" content="telephone=no">
  <meta name="msapplication-tap-highlight" content="no">

  <link rel="icon" type="image/x-icon" href="assets/icon/favicon.ico">
  <link rel="manifest" href="manifest.json">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <meta name="theme-color" content="#4e8ef7">

  <!-- add to homescreen for ios -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <!-- cordova.js required for cordova apps (remove if not needed) -->
  <script src="cordova.js"></script>
  
  
    
  <!-- un-comment this code to enable service worker
  <script>
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.register('service-worker.js')
        .then(() => console.log('service worker installed'))
        .catch(err => console.error('Error', err));
    }
  </script>-->

  <link href="build/main.css" rel="stylesheet">
  <script src="./assets/js/artyom.window.js"></script>
</head>
<body>
  <script src="./assets/js/speaker-recognition-api-demo-core.js"></script>
  <script src="./assets/js/recorder.js"></script>
  
  <!-- Ionic's root component and where the app will load -->
 
  <script>

    var recorder;
    var audio_context;
    var spokenText = '';
    var listeningDone = false;
    artyom =  new Artyom();

    var defaultText = "Transfer 500 Rupees to Karthik"
    //parseString();

    function parseString(spokenText){
      console.log("parseString() with ",spokenText)
      defaultText = localStorage.getItem("spokenText") || spokenText;
      if(defaultText.toLowerCase().startsWith("transfer") ||defaultText.toLowerCase().startsWith("pay") ||defaultText.toLowerCase().startsWith("send")){
        var amount = defaultText.split(" ")[1];
        var payeeContactName = defaultText.split(" ")[4];
        console.log("registering statement in localStorage...")
        localStorage.setItem("amount",amount);
        localStorage.setItem("payeeContactName",payeeContactName);
        //console.log(amount,' to ',payeeContactName);
      }
    }

    var settings = {
      continuous:false, // Don't stop never because i have https connection
      onResult:function(text){
          // text = the recognized text
          console.log(">>>>>> you spoke:",text);
          if(text!=''){
            spokenText = text;
          }
            
      },
      onStart:function(){
          console.log("Dictation started by the user");
      },
      onEnd:function(){
        listeningDone = true;
        console.log("Dictation stopped by the user");
        console.log("Final Text: "+spokenText);
      }
};

  function identifySpeaker(){
    var textInterval = setInterval(()=>{
    console.log("Searching for spokenText..")
    if(localStorage.getItem("listening")!=null && localStorage.getItem("listening")!="true" &&
      localStorage.getItem("recognitionDone")!=null && localStorage.getItem("recognitionDone")=="succeeded"){
      if(localStorage.getItem("speakerRecongized")!=null && localStorage.getItem("speakerRecongized")=="true"){
        clearInterval(textInterval);
        localStorage.removeItem("spokenText");
        localStorage.setItem("spokenText",spokenText);
        setTimeout(()=>{
          parseString(spokenText);
        },500)
        
      }
      clearInterval(textInterval);
    }
    
  },1000);
  }
  

    var UserDictation = artyom.newDictation(settings);
    function onMediaSuccess(stream, callback, secondsOfAudio,captureText) {
        audio_context = audio_context || new window.AudioContext;
        var input = audio_context.createMediaStreamSource(stream);
        recorder = new Recorder(input);
        recorder.record();
        if(localStorage.getItem("enrollmentDone") == "true" && captureText){
          UserDictation.start();
        }
       
      setTimeout(() => { StopListening(callback); }, secondsOfAudio*1000);
    }
    
    function onMediaError(e) {
        console.error('media error', e);
    }
    
    function StopListening(callback,caller){
      console.log('...working...');
        recorder && recorder.stop();
        UserDictation.stop();
        recorder.exportWAV(function(blob) {
            callback(blob,caller);
        });
        recorder.clear();
    }
    
    </script>

  <ion-app></ion-app>
  
  <!-- The polyfills js is generated during the build process -->
  <script src="build/polyfills.js"></script>

  <!-- The vendor js is generated during the build process
       It contains all of the dependencies in node_modules -->
  <script src="build/vendor.js"></script>

  <!-- The main bundle js is generated during the build process -->
  <script src="build/main.js"></script>

</body>
</html>
