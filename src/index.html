<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
  <title>Ionic App</title>
  <meta name="viewport" content="viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="format-detection" content="telephone=no">
  <meta name="msapplication-tap-highlight" content="no">

  <link rel="icon" type="image/x-icon" href="assets/icon/favicon.ico">
  <link rel="manifest" href="manifest.json">
  <meta name="theme-color" content="#4e8ef7">

  <!-- add to homescreen for ios -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <!-- cordova.js required for cordova apps (remove if not needed) -->
  <script src="cordova.js"></script>
  
  
    
  <!-- un-comment this code to enable service worker
  <script>
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.register('service-worker.js')
        .then(() => console.log('service worker installed'))
        .catch(err => console.error('Error', err));
    }
  </script>-->

  <link href="build/main.css" rel="stylesheet">
  <script src="./assets/js/artyom.window.js"></script>
</head>
<body>
  <script src="./assets/js/speaker-recognition-api-demo-core.js"></script>
  <script src="./assets/js/recorder.js"></script>
  
  <!-- Ionic's root component and where the app will load -->
 
  <script>

    var recorder;
    var audio_context;
    artyom =  new Artyom();
    var settings = {
      continuous:false, // Don't stop never because i have https connection
      onResult:function(text){
          // text = the recognized text
          console.log(">>>>>> you sspoke:",text);
      },
      onStart:function(){
          console.log("Dictation started by the user");
      },
      onEnd:function(){
          alert("Dictation stopped by the user");
      }
};
    var UserDictation = artyom.newDictation(settings);
    function onMediaSuccess(stream, callback, secondsOfAudio,captureText) {
        audio_context = audio_context || new window.AudioContext;
        var input = audio_context.createMediaStreamSource(stream);
        recorder = new Recorder(input);
        recorder.record();
        if(localStorage.getItem("enrollmentDone") == "true" && captureText){
          UserDictation.start();
        }
       
      setTimeout(() => { StopListening(callback); }, secondsOfAudio*1000);
    }
    
    function onMediaError(e) {
        console.error('media error', e);
    }
    
    function StopListening(callback,caller){
      console.log('...working...');
        recorder && recorder.stop();
        UserDictation.stop();
        recorder.exportWAV(function(blob) {
            callback(blob,caller);
        });
        recorder.clear();
    }
    
    </script>

  <ion-app></ion-app>
  
  <!-- The polyfills js is generated during the build process -->
  <script src="build/polyfills.js"></script>

  <!-- The vendor js is generated during the build process
       It contains all of the dependencies in node_modules -->
  <script src="build/vendor.js"></script>

  <!-- The main bundle js is generated during the build process -->
  <script src="build/main.js"></script>

</body>
</html>
